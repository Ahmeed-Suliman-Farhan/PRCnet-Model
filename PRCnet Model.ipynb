{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=sorted(os.listdir('E:\\\\archive5\\\\train')) \n",
    "print(names)\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_gen=keras.preprocessing.image.ImageDataGenerator(rescale=1./255,brightness_range=[0.1,0.7],\n",
    "                                                       rotation_range=20,\n",
    "                                                       horizontal_flip=True,\n",
    "                                                       vertical_flip=True,\n",
    "                                                       width_shift_range=0.2,\n",
    "                                                       height_shift_range=0.2)\n",
    "                                                       \n",
    "valid_gen=keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_gen=keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_batches=train_gen.flow_from_directory(\n",
    "    r\"E:\\archive5\\train\",\n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    color_mode=\"grayscale\",\n",
    "    classes=names\n",
    "    )\n",
    "val_batches=valid_gen.flow_from_directory(\n",
    "    r\"E:\\archive5\\val\",\n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    color_mode=\"grayscale\",\n",
    "    classes=names\n",
    "    )\n",
    "test_batches=test_gen.flow_from_directory(\n",
    "    r\"E:\\archive5\\test\",\n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    color_mode=\"grayscale\",\n",
    "    classes=names\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(224,224,1))\n",
    "\n",
    "L1 = layers.Conv2D(32, 3,strides=(2,2), padding=\"same\")(inputs)\n",
    "L1 = layers.BatchNormalization()(L1)\n",
    "L1 = layers.Activation('relu')(L1)\n",
    "# --------------------------------------\n",
    "\n",
    "#-----------------------------------------\n",
    "L2 = layers.Conv2D(64, 3, padding=\"same\")(L1)\n",
    "L2 = layers.BatchNormalization()(L2)\n",
    "L2 = layers.Activation('relu')(L2)\n",
    "#-----------------------------------------\n",
    "L3 = layers.MaxPooling2D(2)(L2)\n",
    "#---------------------------------------------\n",
    "L4 = layers.Conv2D(64, 3, padding=\"same\")(L3)\n",
    "L4 = layers.BatchNormalization()(L4)\n",
    "L4 = layers.Activation('relu')(L4)\n",
    "\n",
    "L5 = layers.Conv2D(64, 5, padding=\"same\")(L3)\n",
    "L5 = layers.BatchNormalization()(L5)\n",
    "L5 = layers.Activation('relu')(L5)\n",
    "\n",
    "L6 = layers.Conv2D(64, 7, padding=\"same\")(L3)\n",
    "L6 = layers.BatchNormalization()(L6)\n",
    "L6 = layers.Activation('relu')(L6)\n",
    "\n",
    "L7 = layers.Concatenate()([L3,L4,L5,L6])\n",
    "L7 = layers.BatchNormalization()(L7)\n",
    "#---------------------------------------------------\n",
    "\n",
    "L8 = layers.Conv2D(128, 3,strides=(2,2), padding=\"same\")(L7)\n",
    "L8 = layers.BatchNormalization()(L8)\n",
    "L8 = layers.Activation('relu')(L8)\n",
    "\n",
    "L9 = layers.Conv2D(128, 5,strides=(2,2), padding=\"same\")(L7)\n",
    "L9 = layers.BatchNormalization()(L9)\n",
    "L9 = layers.Activation('relu')(L9)\n",
    "\n",
    "L10 = layers.Conv2D(128, 7, strides=(2,2), padding=\"same\")(L7)\n",
    "L10 = layers.BatchNormalization()(L10)\n",
    "L10 = layers.Activation('relu')(L10)\n",
    "\n",
    "\n",
    "L3_1 = layers.Conv2D(128, 3,strides=(2,2), padding=\"same\")(L3)\n",
    "L3_1 = layers.BatchNormalization()(L3_1)\n",
    "L3_1 = layers.Activation('relu')(L3_1)\n",
    "\n",
    "L7_1 = layers.MaxPooling2D(2)(L7)\n",
    " \n",
    "\n",
    "L11 = layers.Concatenate()([L3_1,L7_1,L8,L9,L10])\n",
    "L11 = layers.BatchNormalization()(L11)\n",
    "#-----------------------------------------\n",
    "L12 = layers.MaxPooling2D(2)(L11)\n",
    "#-------------------------------------------\n",
    "\n",
    "L13 = layers.Conv2D(256, 3,strides=(2,2), padding=\"same\")(L12)\n",
    "L13 = layers.BatchNormalization()(L13)\n",
    "L13 = layers.Activation('relu')(L13)\n",
    "\n",
    "L14 = layers.Conv2D(256, 5,strides=(2,2), padding=\"same\")(L12)\n",
    "L14 = layers.BatchNormalization()(L14)\n",
    "L14 = layers.Activation('relu')(L14)\n",
    "\n",
    "L15 = layers.Conv2D(256, 7, strides=(2,2), padding=\"same\")(L12)\n",
    "L15 = layers.BatchNormalization()(L15)\n",
    "L15 = layers.Activation('relu')(L15)\n",
    "#===============================================\n",
    "L3_11 = layers.Conv2D(256, 3,strides=(2,2), padding=\"same\")(L3)\n",
    "L3_11 = layers.BatchNormalization()(L3_11)\n",
    "L3_11 = layers.Activation('relu')(L3_11)\n",
    "\n",
    "L3_11 = layers.MaxPooling2D(2)(L3_11)\n",
    "\n",
    "L3_2 = layers.Conv2D(256, 3,strides=(2,2), padding=\"same\")(L3_11)\n",
    "L3_2 = layers.BatchNormalization()(L3_2)\n",
    "L3_2 = layers.Activation('relu')(L3_2)\n",
    "\n",
    "\n",
    "\n",
    "L7_11 = layers.Conv2D(256, 3,strides=(2,2), padding=\"same\")(L7_1)\n",
    "L7_11 = layers.BatchNormalization()(L7_11)\n",
    "L7_11 = layers.Activation('relu')(L7_11)\n",
    "\n",
    "L7_2 = layers.MaxPooling2D(2)(L7_11)\n",
    "\n",
    "L12_1 = layers.MaxPooling2D(2)(L12)\n",
    " \n",
    "\n",
    "L16 = layers.Concatenate()([L3_2,L7_2,L12_1,L13,L14,L15])\n",
    "L16 = layers.BatchNormalization()(L16)\n",
    " \n",
    "x = layers.GlobalAveragePooling2D()(L16)\n",
    "\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(4, activation='softmax')(x)\n",
    " \n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"Our_model\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "#optim=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#metrics=[\"accuracy\"]\n",
    " \n",
    "#model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "\n",
    "optim=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optim, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "  \n",
    "n_epochs = 250\n",
    " \n",
    "\n",
    "\n",
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "\n",
    "plot_loss_1 = PlotLossesCallback()\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='E:\\\\Four_class_classification_without_Augmentation.weights.best.hdf5',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping - monitors the performance of the model and stopping the training process prevents overtraining\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                         patience=40,\n",
    "                          restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           epochs=n_epochs,\n",
    "                           validation_data=val_batches,\n",
    "                           callbacks=[tl_checkpoint_1, early_stop],\n",
    "                            verbose=2)\n",
    "#history=model.fit(train_batches,validation_data=val_batches,batch_size=BATCH_SIZE,\n",
    "#                 epochs=epochs, verbose=2)    validation_steps=n_val_steps,\n",
    "                          #steps_per_epoch=n_steps,\n",
    "model.save('E:\\\\Four_class_classification_without_Augmentation.h5')\n",
    " \n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1) \n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='valid loss')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='valid acc')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c768d86",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.load_weights('E:\\\\Four_class_classification_without_Augmentation.weights.best.hdf5') # load  the best trained weights\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds_ft = model.predict(test_batches)\n",
    "pred_classes_ft = np.argmax(preds_ft, axis=1)\n",
    "true_classes = test_batches.classes\n",
    "acc_ft = accuracy_score(true_classes, pred_classes_ft)\n",
    "print(\"Our Model Accuracy for data test: {:.2f}%\".format(acc_ft * 100))\n",
    "\n",
    "\n",
    "class_names = test_batches.class_indices.keys()\n",
    " \n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, ax, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sn.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        square=True, \n",
    "        xticklabels=class_names, \n",
    "        yticklabels=class_names,\n",
    "        fmt='d', \n",
    "        cmap=plt.cm.Blues,\n",
    "        cbar=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel('True Label', fontsize=12)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "fig, ( ax1) = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "   \n",
    "plot_confusion_matrix(true_classes, pred_classes_ft, class_names, ax1, title=\"test data on our model\")    \n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=1.25)\n",
    "plt.show()\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy score is :', np.round(metrics.accuracy_score(true_classes, pred_classes_ft),4))\n",
    "print('Precision score is :', np.round(metrics.precision_score(true_classes, pred_classes_ft, average='macro'),4))\n",
    "print('Recall score is :', np.round(metrics.recall_score(true_classes, pred_classes_ft, average='macro'),4))\n",
    "print('F1 Score is :', np.round(metrics.f1_score(true_classes, pred_classes_ft, average='macro'),4))\n",
    " \n",
    "print('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(true_classes, pred_classes_ft),4))\n",
    "\n",
    "print('\\t\\tClassification Report:\\n', metrics.classification_report(true_classes, pred_classes_ft))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ah21)",
   "language": "python",
   "name": "ah21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
